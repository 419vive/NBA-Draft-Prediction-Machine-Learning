NBA Draft Prediction Workflow

Step 1: Data Extraction

ðŸ“¥ Connect to SQLite database.
ðŸ“¥ Extract data from relevant tables: Player_Attributes, Team_Salary, Player_Salary, Draft, Draft_Combine, Game.
ðŸ“¥ Merge Draft and Draft_Combine tables.
ðŸ“¥ Drop unnecessary columns containing 'set' and 'location'.

Step 2: Data Cleaning

ðŸ§¼ Handle missing values by filling with mode (categorical) or mean (numerical).
ðŸ§¼ Drop irrelevant or redundant rows and columns.
ðŸ§¼ Verify data integrity by inspecting cleaned data.

Step 3: Feature Engineering

ðŸ›  Select relevant features based on domain knowledge.
ðŸ›  Create new columns to capture positional data.
ðŸ›  Calculate additional metrics (e.g., BMI).

Step 4: Exploratory Data Analysis (EDA)

ðŸ” Display summary statistics and distributions of key features.
ðŸ” Analyze the distribution of the target variable (drafted).
ðŸ” Visualize relationships and correlations between features.

Step 5: Data Transformation

ðŸ”„ Normalize or scale numerical features.
ðŸ”„ Apply one-hot encoding to categorical features.
ðŸ”„ Split data into training, validation, and test sets.

Step 6: Model Selection and Training

ðŸ§  Choose a variety of models (e.g., Logistic Regression, Decision Tree, Random Forest, SVM, KNN, Gradient Boosting, XGBoost).
ðŸ§  Train models using training data.
ðŸ§  Evaluate models using metrics like accuracy, precision, recall, F1 score, ROC-AUC, and specificity.

Step 7: Model Evaluation and Interpretation

ðŸ“Š Compare model performance based on evaluation metrics.
ðŸ“Š Select the best model based on desired metric (e.g., recall).
ðŸ“Š Perform feature importance analysis to identify key predictors.

Step 8: Model Deployment

ðŸš€ Save the best-performing model.
ðŸš€ Load and use the model for real-time predictions.

Step 9: SHAP Analysis for Model Interpretation

ðŸ” Generate SHAP values to explain model predictions.
ðŸ” Create SHAP decision plots for individual player analysis.

Step 10: Real-World Application

ðŸ€ Gather real data for new players (e.g., Kevin Durant, Bronny James).
ðŸ€ Apply feature engineering and standardization.
ðŸ€ Predict draft status and interpret results using the saved model and SHAP analysis.






import sqlite3
import pandas as pd

# é€£æŽ¥åˆ° SQLite è³‡æ–™åº«
conn = sqlite3.connect('/Users/jerrylaivivemachi/Desktop/basketball.sqlite')

# æå–è¡¨æ ¼æ•¸æ“š
player_attributes_df = pd.read_sql('SELECT * FROM Player_Attributes', conn)
team_salary_df = pd.read_sql('SELECT * FROM Team_Salary', conn)
player_salary_df = pd.read_sql('SELECT * FROM Player_Salary', conn)
draft_df = pd.read_sql('SELECT * FROM Draft', conn)
draft_combine_df = pd.read_sql('SELECT * FROM Draft_Combine', conn)
games_df = pd.read_sql('SELECT * FROM Game', conn)

# åˆä½µ Draft å’Œ Draft_Combine è¡¨æ ¼
merged_df = pd.merge(draft_df, draft_combine_df, on='idPlayer', how='right')

# åˆªé™¤åŒ…å« 'set' å’Œ 'location' å­—æ¨£çš„åˆ—
columns_to_drop = [col for col in merged_df.columns if 'set' in col or 'location' in col]
merged_df.drop(columns=columns_to_drop, inplace=True)

cols_to_drop = ['heightWShoesInches', 'heightWShoes']
merged_df.drop(cols_to_drop, axis=1, inplace=True)

# æ‰“å°åˆä½µä¸”æ•´ç†å¾Œçš„è¡¨æ ¼
print(merged_df.head())

merged_df.info()

import pandas as pd

# è¨­ç½®é¡¯ç¤ºé¸é …ä»¥é¡¯ç¤ºæ‰€æœ‰åˆ—å’Œæ‰€æœ‰è¡Œ
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

merged_df.loc[:, ('yearCombine')] = merged_df['yearCombine'].apply(lambda x: x - 1)

merged_df[~(merged_df.isna())][['yearDraft', 'yearCombine', 'namePlayer_y']]

# create a target variable, drafted
merged_df.loc[:, 'drafted'] = (merged_df.yearDraft > 0)

merged_df.drafted.value_counts()

# check that yearDraft
merged_df[merged_df.yearDraft < 2000]

# Drop the mistaken row for Reggie Williams
merged_df = merged_df.drop(index=693, axis=0)

merged_df.info()

# é—œé–‰è³‡æ–™åº«é€£æŽ¥
conn.close()

# Step 2: Data Cleaning

# è™•ç†ç¼ºå¤±å€¼çš„å‡½æ•¸ï¼Œé‡å°æ•¸å€¼åž‹å’Œåˆ†é¡žåž‹æ•¸æ“šåˆ†åˆ¥è™•ç†
def handle_missing_values(df):
    for column in df.columns:
        if df[column].dtype == 'object':
            # ç”¨çœ¾æ•¸å¡«å……åˆ†é¡žåž‹ç¼ºå¤±å€¼
            df[column].fillna(df[column].mode()[0], inplace=True)
        else:
            # ç”¨å¹³å‡å€¼å¡«å……æ•¸å€¼åž‹ç¼ºå¤±å€¼
            df[column].fillna(df[column].mean(), inplace=True)
    return df

# è™•ç† merged_df ä¸­çš„ç¼ºå¤±å€¼
merged_df = handle_missing_values(merged_df)

# è™•ç†å…¶ä»–æ•¸æ“šè¡¨ä¸­çš„ç¼ºå¤±å€¼
player_attributes_df = handle_missing_values(player_attributes_df)
team_salary_df = handle_missing_values(team_salary_df)
player_salary_df = handle_missing_values(player_salary_df)
games_df = handle_missing_values(games_df)

# æ‰“å°è™•ç†å¾Œçš„ merged_df ä¾†ç¢ºèªçµæžœ
print(merged_df.head())

# As an NBA subject matter expert (i.e. basketball fan), this is what I think to be useful features. The rest of the columns are mostly organization names etc. which have high cardinality and difficult to be used as features

feature_list = [
    'idPlayer', 'namePlayer_y', 'yearDraft', 'yearCombine', 'numberPickOverall', 'slugPosition', 'heightWOShoesInches',
    'weightLBS', 'wingspanInches', 'reachStandingInches', 'verticalLeapStandingInches', 'verticalLeapMaxInches', 'repsBenchPress135',
    'timeLaneAgility', 'timeThreeQuarterCourtSprint', 'timeModifiedLaneAgility', 'lengthHandInches', 'widthHandInches', 'pctBodyFat', 'drafted'
    ]

merged_df = merged_df[feature_list]

merged_df.head()

# slugPosition
unique_position = merged_df.slugPosition.unique()
unique_position

# There are some positions that are double, meaning the players can play two positions with the first position being the primary position. We can just create another column to capture this information instead of having 14 unique positions.

merged_df[['primary_position', 'secondary_position']] = merged_df['slugPosition'].str.split('-', expand=True)

merged_df.head()

# EDA æ­¥éª¤
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# æŸ¥çœ‹åŸºæœ¬ä¿¡æ¯
print(merged_df.info())

The dataset consists of 1,394 entries and 22 columns, containing a mix of numerical and categorical data related to NBA players' draft and combine statistics. Key columns include player identifiers, names, draft years, combine years, and various physical and performance metrics such as height without shoes, weight, wingspan, standing reach, vertical leap, agility times, and hand measurements. Most columns have complete data, except for the secondary position, which has significant missing values (only 496 non-null entries). This dataset appears well-prepared for an analysis aimed at understanding the physical and performance characteristics that influence draft outcomes, but special attention may be needed to handle the missing values in the secondary position and to ensure all relevant features are appropriately processed and normalized for model training.

# æŸ¥çœ‹ç»Ÿè®¡æè¿°
print(merged_df.describe(include='all'))

## Key Observations

### Unique Values and Frequencies
- **Players**: The dataset includes data for 1,366 unique players.
- **Positions**: Players are categorized into 14 unique positions, with Power Forward (PF) being the most frequent.
- **Drafted Players**: 808 players are marked as drafted, while the remaining 586 are not.

### Descriptive Statistics
- **yearDraft**: The data spans from 2000 to 2020, with a mean draft year of 2010.7.
- **yearCombine**: The combine years range from 2000 to 2020, with a mean of 2009.4.
- **Height without Shoes**: Ranges from 67.75 to 89.25 inches, with a mean of 77.6 inches.
- **Weight**: Ranges from 149.2 to 334 pounds, with a mean of 216.1 pounds.
- **Wingspan**: Ranges from 70 to 98.25 inches, with a mean of 82.4 inches.
- **Standing Reach**: Ranges from 88.5 to 122.5 inches, with a mean of 103.4 inches.
- **Vertical Leap (Standing and Max)**: Standing leap ranges from 19.5 to 39.5 inches, with a mean of 29.2 inches. Max leap ranges from 21 to 45.5 inches, with a mean of 34.4 inches.
- **Bench Press**: Repetitions range from 0 to 27, with a mean of 10.3 reps.
- **Agility and Sprint Times**: Lane agility ranges from 9.65 to 14.45 seconds, with a mean of 11.4 seconds. Three-quarter court sprint times range from 2.91 to 3.81 seconds, with a mean of 3.29 seconds.
- **Hand Measurements**: Hand length ranges from 7.5 to 10.5 inches, with a mean of 8.7 inches. Hand width ranges from 7 to 12 inches, with a mean of 9.4 inches.
- **Body Fat Percentage**: Ranges from 2.6% to 23.1%, with a mean of 7.6%.

### Missing Values
- **Secondary Position**: Only 496 entries have a recorded secondary position, indicating significant missing data in this column.

### Most Frequent Categories
- **Most Common Player Name**: Josh Hart, appearing twice.
- **Most Common Primary Position**: Power Forward (PF) with 376 occurrences.
- **Most Common Secondary Position**: Small Forward (SF) with 143 occurrences.

## Insights and Implications

### Insights
1. **Player Physical Profiles**: The data reveals that successful draftees generally have a balanced physical profile with above-average height, weight, and wingspan.
2. **Performance Metrics**: Metrics such as vertical leap, bench press reps, and agility times are crucial indicators of a player's athleticism and can be strong predictors of draft success.
3. **Position Flexibility**: The presence of players with multiple positions indicates the importance of versatility in the modern NBA, though the secondary position data is sparse.

### Implications and Applications
1. **Scouting and Recruitment**: Teams can use this data to identify key physical and performance benchmarks for potential draftees. By comparing current prospects against historical data, scouts can better assess a player's likelihood of success in the NBA.
2. **Training and Development**: Coaches can tailor training programs to improve critical performance metrics identified in the data, such as agility and vertical leap, to enhance a player's draft prospects.
3. **Draft Strategy**: General managers can leverage the insights from this data to develop more informed draft strategies, focusing on players who exhibit the physical and performance characteristics correlated with successful NBA careers.
4. **Predictive Modeling**: This dataset provides a solid foundation for building predictive models to forecast draft outcomes. By analyzing historical patterns, teams can better predict which players are likely to be drafted and succeed in the NBA.

## Summary
The dataset provides a comprehensive view of the physical and performance attributes of NBA players, offering valuable insights for scouting, training, and draft strategies. Addressing the missing data in the secondary position column will further enhance the dataset's utility, ensuring more robust and unbiased analyses.


# æ£€æŸ¥ç¼ºå¤±å€¼æƒ…å†µ
missing_values = merged_df.isnull().sum()
print(missing_values[missing_values > 0])

# è®¾å®š Seaborn æ ·å¼
sns.set(style="darkgrid")
plt.style.use("dark_background")

# æ•°å€¼åž‹ç‰¹å¾çš„ç›´æ–¹å›¾
numeric_features = merged_df.select_dtypes(include=[np.number]).columns

# åˆ›å»ºFacetGridæ¥å±•ç¤ºå¤šä¸ªç›´æ–¹å›¾
g = sns.FacetGrid(pd.melt(merged_df[numeric_features]), col="variable", col_wrap=4, sharex=False, sharey=False)
g.map(sns.histplot, "value", kde=True, color='skyblue')

# è°ƒæ•´å¸ƒå±€å’Œæ ‡é¢˜
g.fig.subplots_adjust(top=0.9)
g.fig.suptitle('Distribution of Numeric Features', fontsize=16)

plt.show()

# Senior Data Analyst Report: Histogram Analysis of Numeric Features

## Overview
The histogram analysis of the numeric features in the NBA draft dataset reveals the distribution and central tendencies of various physical and performance metrics of the players. This analysis helps in understanding the underlying patterns and identifying any anomalies or trends within the data.

## Key Observations

### idPlayer
- **Distribution**: Highly skewed with most values clustered around a specific range.
- **Implication**: The `idPlayer` feature is a unique identifier and doesn't provide useful information for analysis.

### yearDraft
- **Distribution**: The data shows a significant number of players drafted around the years 2010 and 2015.
- **Implication**: This indicates that the dataset includes a balanced mix of players from different draft years, with some peaks in specific years.

### yearCombine
- **Distribution**: Similar to `yearDraft`, with noticeable peaks around 2004 and 2015.
- **Implication**: The combine data follows a similar pattern to the draft data, reflecting the years players attended the combine.

### numberPickOverall
- **Distribution**: Peaks at lower pick numbers, indicating a higher frequency of players picked early in the draft.
- **Implication**: This suggests that the dataset includes more top-picked players, which could influence the analysis towards higher-performing individuals.

### heightWOShoesInches
- **Distribution**: Roughly normal distribution centered around 77.6 inches.
- **Implication**: Indicates a typical height range for NBA players, with most players falling within a few inches of the mean.

### weightLBS
- **Distribution**: Approximately normal distribution centered around 216.1 pounds.
- **Implication**: Reflects the average weight of NBA players, providing insights into the typical body mass.

### wingspanInches
- **Distribution**: Normal distribution with a mean of 82.4 inches.
- **Implication**: Suggests a standard wingspan range for NBA players, important for assessing player reach.

### reachStandingInches
- **Distribution**: Normal distribution with a mean of 103.4 inches.
- **Implication**: Indicates the typical standing reach of players, crucial for evaluating defensive and offensive capabilities.

### verticalLeapStandingInches
- **Distribution**: Roughly normal distribution centered around 29.2 inches.
- **Implication**: Provides insights into the explosive power of players, which is critical for rebounding and shot-blocking.

### verticalLeapMaxInches
- **Distribution**: Normal distribution with a mean of 34.4 inches.
- **Implication**: Reflects the maximum vertical leap, highlighting players' athleticism.

### repsBenchPress135
- **Distribution**: Skewed distribution with most values clustered around 10.3 reps.
- **Implication**: Indicates the upper body strength of players, important for physical play in the NBA.

### timeLaneAgility
- **Distribution**: Approximately normal distribution centered around 11.4 seconds.
- **Implication**: Reflects players' agility, crucial for quick movements on the court.

### timeThreeQuarterCourtSprint
- **Distribution**: Normal distribution with a mean of 3.29 seconds.
- **Implication**: Highlights the sprint speed of players, important for fast breaks and defensive recovery.

### timeModifiedLaneAgility
- **Distribution**: Contains some anomalies, with most values clustered around a specific point.
- **Implication**: Suggests potential issues with the data collection or specific scenarios affecting the recorded times.

### lengthHandInches
- **Distribution**: Normal distribution centered around 8.7 inches.
- **Implication**: Reflects typical hand length, relevant for ball handling and shooting.

### widthHandInches
- **Distribution**: Normal distribution centered around 9.4 inches.
- **Implication**: Indicates hand width, which can impact grip and control of the ball.

### pctBodyFat
- **Distribution**: Skewed distribution with most values clustered around 7.6%.
- **Implication**: Shows the body fat percentage of players, important for assessing physical fitness and conditioning.

## Summary
The histograms reveal that most physical and performance metrics follow a roughly normal distribution, with a few features exhibiting skewness or anomalies. These insights can help in understanding the typical profiles of NBA players and identifying any outliers or trends in the data. This information is crucial for scouting, training, and predictive modeling in basketball analytics.


# ç›®æ ‡å˜é‡çš„åˆ†å¸ƒæƒ…å†µ
plt.figure(figsize=(10, 6))
sns.countplot(x=merged_df['drafted'], palette="Blues_r")
plt.title('Distribution of Target Variable (drafted)', fontsize=16)
plt.xlabel('Drafted', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.show()

# Data Analyst Report: Target Variable Distribution

## Overview
The bar chart shows the distribution of the target variable, `drafted`, in the NBA draft dataset. This variable indicates whether a player was drafted (True) or not (False).

## Key Observations
1. **Count of Drafted Players**:
   - **True (Drafted)**: Approximately 808 players.
   - **False (Not Drafted)**: Approximately 586 players.
   
2. **Distribution Balance**:
   - The dataset shows a higher number of drafted players compared to undrafted players.
   - This indicates a relatively balanced dataset, but with a slight skew towards players who were drafted.

## Implications
1. **Model Training**:
   - The relatively balanced distribution of the target variable is beneficial for training machine learning models. It helps in preventing the model from being biased towards one class.
   - The presence of a sufficient number of both drafted and undrafted players will allow the model to learn the distinguishing features effectively.

2. **Performance Metrics**:
   - With a balanced target variable, standard performance metrics such as accuracy, precision, recall, and F1 score will be reliable indicators of model performance.
   - Specific metrics like specificity and sensitivity will also provide meaningful insights into the modelâ€™s ability to distinguish between drafted and undrafted players.

3. **Model Bias**:
   - Although there is a slight skew towards drafted players, it is not significant enough to cause major concern. However, techniques like stratified sampling can be used during model training to ensure even better balance.

## Recommendations
1. **Data Augmentation**:
   - Consider data augmentation techniques if more data becomes available, especially for the undrafted class, to further balance the dataset.
   
2. **Model Evaluation**:
   - Ensure thorough evaluation using a variety of metrics to capture the modelâ€™s performance comprehensively.
   - Pay attention to both classes (drafted and undrafted) during model validation to avoid any potential bias.

## Summary
The distribution of the target variable `drafted` shows a slightly higher number of drafted players compared to undrafted players. This distribution is beneficial for training robust machine learning models, allowing for effective learning and accurate predictions. However, maintaining a close balance in the target variable distribution is crucial for unbiased model performance.


# ç›¸å…³çŸ©é˜µ
numeric_df = merged_df.select_dtypes(include=[np.number])
corr_matrix = numeric_df.corr()
print(corr_matrix)

# çƒ­åŠ›å›¾
plt.figure(figsize=(14, 12))
sns.heatmap(corr_matrix, annot=True, cmap="Blues_r", fmt=".2f")
plt.title('Correlation Matrix', fontsize=16)
plt.show()


# Senior Data Analyst Report: Correlation Analysis

## Overview
The correlation matrix provides insights into the relationships between various numeric features in the NBA draft dataset. By examining these correlations, we can understand which attributes are closely related and how they might influence each other. This information is crucial for feature selection, predictive modeling, and understanding the underlying data structure.

## Key Observations

### Strong Positive Correlations
1. **heightWOShoesInches and reachStandingInches (0.920)**:
   - **Insight**: Taller players tend to have a greater standing reach.
   - **Implication**: This relationship is expected and confirms that height is a key factor in reach. In practice, scouting reports can use either metric interchangeably to some extent.

2. **heightWOShoesInches and wingspanInches (0.836)**:
   - **Insight**: Taller players generally have a longer wingspan.
   - **Implication**: Both height and wingspan are critical for defensive and offensive capabilities in basketball. This reinforces the importance of these metrics in player evaluation.

3. **verticalLeapStandingInches and verticalLeapMaxInches (0.839)**:
   - **Insight**: Players who perform well in standing vertical leap also excel in maximum vertical leap.
   - **Implication**: Vertical leap measurements can be indicative of a player's explosive power, which is crucial for rebounding and shot-blocking. Training programs can focus on improving vertical leap to enhance overall athletic performance.

### Moderate Positive Correlations
1. **weightLBS and heightWOShoesInches (0.755)**:
   - **Insight**: Heavier players tend to be taller.
   - **Implication**: This relationship is important for understanding player build and conditioning. Teams can use this information to tailor fitness and nutrition programs based on player profiles.

2. **timeLaneAgility and timeThreeQuarterCourtSprint (0.485)**:
   - **Insight**: Players with good agility tend to have better sprint times.
   - **Implication**: Agility and sprint times are critical for fast breaks and defensive coverage. Coaches can use these metrics to identify and develop players suited for high-tempo playstyles.

### Weak and Negative Correlations
1. **verticalLeapMaxInches and timeThreeQuarterCourtSprint (-0.580)**:
   - **Insight**: Players with higher maximum vertical leap tend to have faster sprint times.
   - **Implication**: This suggests that players with explosive power are also generally faster. This can be used to identify versatile athletes who can excel in multiple aspects of the game.

2. **pctBodyFat and verticalLeapMaxInches (-0.415)**:
   - **Insight**: Higher body fat percentages are associated with lower maximum vertical leap.
   - **Implication**: Body composition significantly affects athletic performance. Teams should focus on optimizing body fat levels to enhance player agility and leaping ability.

3. **heightWOShoesInches and verticalLeapStandingInches (-0.262)**:
   - **Insight**: Taller players may have slightly lower standing vertical leaps.
   - **Implication**: This could indicate that taller players rely more on their height and less on their vertical jumping ability. Training programs should consider this when developing exercises tailored to different player builds.

### Additional Insights
- **Time-Related Metrics**: Correlations between various agility and sprint times (e.g., timeLaneAgility and timeThreeQuarterCourtSprint) highlight the importance of speed and agility in player performance. These metrics are vital for positions that require quick movements and transitions.

- **Hand Measurements**: Correlations between hand length and width with other physical metrics (e.g., height, weight) suggest that larger hand sizes may be associated with overall larger body frames. This can be useful for ball handling and control.

## Practical Applications
1. **Scouting and Recruitment**:
   - Utilize strong positive correlations to identify key attributes that predict overall player potential. For example, height and wingspan can be used to assess defensive capabilities.

2. **Training and Development**:
   - Focus on improving agility and sprint times for positions requiring quick movements. Use vertical leap metrics to enhance explosive power and rebounding skills.

3. **Predictive Modeling**:
   - Use the identified correlations to select relevant features for predictive models. Strongly correlated features can improve model accuracy and provide more reliable predictions.

4. **Injury Prevention**:
   - Monitor body fat percentages and conditioning to reduce the risk of injuries and improve performance metrics such as agility and vertical leap.

5. **Player Positioning**:
   - Use physical and performance metrics to determine the best positions for players based on their strengths. For example, taller players with good wingspan may be more suited for forward or center positions.

## Summary
The correlation analysis reveals significant relationships between various physical and performance metrics of NBA players. These insights can be applied in scouting, training, predictive modeling, and overall player development to enhance team performance and player capabilities.


# æ•°å€¼åž‹ç‰¹å¾ä¸Žç›®æ ‡å˜é‡çš„å…³ç³»
numeric_features = merged_df.select_dtypes(include=[np.number]).columns

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# å°†æ•°æ®è½¬æ¢ä¸ºé€‚åˆFacetGridæ ¼å¼çš„é•¿æ ¼å¼
melted_df = pd.melt(merged_df, id_vars=['drafted'], value_vars=numeric_features)

# åˆ›å»ºFacetGridæ¥å±•ç¤ºå¤šä¸ªç®±çº¿å›¾
g = sns.FacetGrid(melted_df, col="variable", col_wrap=4, sharex=False, sharey=False)
g.map(sns.boxplot, 'drafted', 'value', palette="Blues_r")

# è°ƒæ•´å¸ƒå±€å’Œæ ‡é¢˜
g.fig.subplots_adjust(top=0.9)
g.fig.suptitle('Relationship between Numeric Features and Target Variable (drafted)', fontsize=16)

plt.show()


# Step 3: Data Transformation
# Normalize or Scale Features

from sklearn.preprocessing import StandardScaler

# é«˜ç´šç‰¹å¾µå·¥ç¨‹å‡½æ•¸
def feature_engineering(df):
    # Convert weight from pounds (lbs) to kilograms (kg)
    df['weightKG'] = df['weightLBS'] * 0.453592

    # Convert height from inches (in) to meters (m)
    df['heightM'] = df['heightWOShoesInches'] * 0.0254

    # Calculate BMI using the converted values
    df['BMI'] = df['weightKG'] / (df['heightM'] ** 2)
    
    return df

# å° merged_df é€²è¡Œç‰¹å¾µå·¥ç¨‹
merged_df = feature_engineering(merged_df)

# æ‰“å°é€²è¡Œç‰¹å¾µå·¥ç¨‹å¾Œçš„ merged_df ä¾†ç¢ºèªçµæžœ
print(merged_df.head())

# ç‰¹å¾µæ¨™æº–åŒ–
from sklearn.preprocessing import StandardScaler 
import numpy as np

scaler = StandardScaler()
numeric_features = merged_df.select_dtypes(include=[np.number]).columns
merged_df[numeric_features] = scaler.fit_transform(merged_df[numeric_features])

# æ‰“å°é€²è¡Œç‰¹å¾µå·¥ç¨‹å¾Œçš„ merged_df ä¾†ç¢ºèªçµæžœ
print(merged_df.head())

# 5.2 Split Data into Training, Validation, and Test Sets

from sklearn.model_selection import train_test_split

# é¸æ“‡ç‰¹å¾µå’Œç›®æ¨™è®Šé‡
# å‡è¨­ 'drafted' æ˜¯æˆ‘å€‘çš„ç›®æ¨™è®Šé‡ï¼Œå…¶ä»–æ•¸å€¼åž‹åˆ—ç‚ºç‰¹å¾µ

X = merged_df.drop(columns=['drafted', 'idPlayer', 'namePlayer_y', 'yearDraft', 'numberPickOverall','heightWOShoesInches','weightLBS'], axis=1)
y = merged_df['drafted']

print(X.columns)

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# ç¢ºä¿æ‰€æœ‰ç‰¹å¾µåˆ—éƒ½æ˜¯æ•¸å€¼åž‹æ•¸æ“š
# å°‡åˆ†é¡žæ•¸æ“šé€²è¡ŒOne-Hotç·¨ç¢¼
numeric_features = X.select_dtypes(include=[np.number]).columns
categorical_features = X.select_dtypes(include=[object]).columns

# å‰µå»ºé è™•ç†ç®¡é“
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ]), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

# å°‡é è™•ç†å™¨æ‡‰ç”¨æ–¼æ•¸æ“š
X_preprocessed = preprocessor.fit_transform(X)

# å°†æ•¸æ“šåˆ†ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42, ) 

# æ‰“å°æ•¸æ“šé›†çš„å½¢ç‹€ä»¥ç¢ºèªåˆ†å‰²
print("Training set shape:", X_train.shape, y_train.shape)
print("Test set shape:", X_test.shape, y_test.shape)





# Step 6: Model Selection

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.metrics import make_scorer
import pandas as pd



# è®¡ç®— scale_pos_weight
scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]

# æ¨¡åž‹åˆ—è¡¨
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(class_weight='balanced'),
    'Support Vector Machine': SVC(probability=True),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight)  # åŠ¨æ€è®¡ç®—çš„æƒé‡
}


# è‡ªå®šç¾© Specificity è©•åˆ†å‡½å¼
def specificity_score(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return tn / (tn + fp) if (tn + fp) != 0 else 0

# å®šç¾©è©•åˆ†å­—å…¸ä¾†å¹³è¡¡å¤šå€‹è©•åˆ†æ¨™æº–
scoring = {
    'specificity': make_scorer(specificity_score),
    'accuracy': 'accuracy',
    'precision': 'precision_weighted',
    'recall': 'recall_weighted',
    'f1': 'f1_weighted'
}

# è¨“ç·´å’Œè©•ä¼°æ¨¡åž‹ï¼Œå­˜å„²çµæžœ
def train_and_evaluate(models, X_train, y_train, X_test, y_test):
    results = {}
    for model_name, model in models.items():
        try:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            y_pred_prob = model.predict_proba(X_test)[:, 1]

            # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')
            f1 = f1_score(y_test, y_pred, average='weighted')
            roc_auc = roc_auc_score(y_test, y_pred_prob)

            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
            specificity = tn / (tn + fp) if (tn + fp) != 0 else 'N/A'

            results[model_name] = {
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall,
                'F1 Score': f1,
                'ROC-AUC': roc_auc,
                'Specificity': specificity
            }
        except Exception as e:
            print(f"Error evaluating model {model_name}: {e}")
    return results

# è¨“ç·´å’Œè©•ä¼°åˆå§‹æ¨¡åž‹
initial_results = train_and_evaluate(models, X_train, y_train, X_test, y_test)

# æ¯”è¼ƒåˆå§‹çµæžœ
comparison_metrics = {}

# åŠ å…¥åˆå§‹æ¨¡åž‹çš„çµæžœ
for model_name, metrics in initial_results.items():
    comparison_metrics[model_name] = {
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1 Score': metrics['F1 Score'],
        'ROC-AUC': metrics['ROC-AUC'],
        'Specificity': metrics['Specificity']
    }

# å°‡çµæžœè½‰æ›ç‚º pandas æ•¸æ“šæ¡†
comparison_df = pd.DataFrame(comparison_metrics).T

# é¡¯ç¤ºæ•¸æ“šæ¡†
print(comparison_df)

Focusing on Recall (Sensitivity) for NBA Draft Prediction
Prioritizing recall in NBA draft prediction ensures accurate identification of all potential draftees, minimizing false negatives where a drafted player is predicted as not drafted. High recall is critical as it ensures comprehensive identification and thorough evaluation of all potential talents, reducing the risk of overlooking key players who could significantly impact the team. Here, we compare the recall performance across different models to highlight which best minimizes the risk of false negatives, ensuring comprehensive identification of potential draftees. Conclusion:
Focusing on recall in this context ensures that the model minimizes false negatives, thereby identifying all potential draftees accurately. Among the evaluated models, Gradient Boosting emerges as the best performer with the highest recall (0.642), ensuring comprehensive identification of drafted players. This is crucial for thorough scouting and reducing the risk of overlooking talented players.


import matplotlib.pyplot as plt
import seaborn as sns

# Train Gradient Boosting model
model = GradientBoostingClassifier()
model.fit(X_train, y_train)

# Extract feature importances
importances = model.feature_importances_

# Get all feature names from preprocessor
numeric_feature_names = preprocessor.transformers_[0][2]
categorical_feature_names = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)
all_feature_names = np.concatenate([numeric_feature_names, categorical_feature_names])

# Create a DataFrame for feature importances
feature_importances_df = pd.DataFrame({
    'Feature': all_feature_names,
    'Importance': importances
})

# Filter features with importance > 0.02
important_features_df = feature_importances_df[feature_importances_df['Importance'] > 0.02]
print(important_features_df)

# Sort the important features in descending order
important_features_df = important_features_df.sort_values(by='Importance', ascending=False)

# Visualize the important features
plt.figure(figsize=(12, 8))
sns.barplot(data=important_features_df, x='Importance', y='Feature', palette='Blues_r')
plt.title('Important Features (Importance > 0.02)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

NBA Draft Prediction Feature Importance Analysis
Overview
The following analysis evaluates the relative importance of various features in predicting NBA Draft outcomes. The importance scores, derived from a Gradient Boosting model, provide insights into which attributes most significantly impact a player's draft status.

Feature Importance Breakdown
Year Combine (0.2126)

Analysis: The year a player participated in the NBA Combine holds the highest importance. This suggests that recent performances and measurements are critical in draft considerations, possibly due to the evolving athletic standards and expectations over time.
Implication: Teams might be prioritizing recent data to assess a player's current form and potential improvements, reflecting the fast-paced nature of athletic development.
Body Fat Percentage (0.0905)

Analysis: Body fat percentage is the second most important feature. Lower body fat is often associated with better agility and endurance, key factors in a player's on-court performance.
Implication: This metric helps teams evaluate a player's physical conditioning and readiness for the demands of professional basketball.
Lane Agility Time (0.0815)

Analysis: Agility is crucial for both offensive maneuvers and defensive positioning. This feature's high importance underscores the need for players to exhibit quick lateral movements and overall agility.
Implication: Scouts and teams are likely using this metric to assess a player's potential to keep up with the fast pace of NBA games and to effectively guard opponents.
Standing Vertical Leap (0.0691)

Analysis: The standing vertical leap measures explosive power, essential for rebounding and shot-blocking.
Implication: This metric is particularly important for positions that rely on jumping ability, such as forwards and centers.
Body Mass Index (0.0690)

Analysis: BMI provides a general indication of a player's body composition, combining height and weight. It is a useful measure to ensure players have an optimal balance between muscle and fat.
Implication: Teams use BMI to gauge a player's physical fitness and potential durability over an NBA season.
Height (0.0680)

Analysis: Height remains a significant factor, influencing a player's reach and ability to shoot or defend effectively.
Implication: Taller players generally have an advantage in both offensive and defensive plays, making this a critical metric for scouts.
Wingspan (0.0593)

Analysis: A player's wingspan affects their defensive coverage and ability to disrupt shots and passes.
Implication: A longer wingspan is highly desirable for positions that require extensive defensive responsibilities.
Standing Reach (0.0535)

Analysis: Standing reach is a measure of how high a player can reach without jumping, important for rebounding and blocking shots.
Implication: This feature is especially relevant for interior players who need to control the paint area.
Bench Press Reps (0.0434)

Analysis: The number of bench press repetitions at 185 lbs indicates upper body strength, contributing to physical play and endurance.
Implication: Strength metrics help teams assess a player's ability to withstand physical challenges during games.
Hand Width (0.0412)

Analysis: Hand width can influence a player's ball-handling skills and grip strength, crucial for shooting and passing.
Implication: Larger hands can provide better control of the basketball, an important trait for guards and forwards.
Max Vertical Leap (0.0390)

Analysis: This measures a player's peak jumping ability, important for both offensive plays like dunking and defensive plays like blocking.
Implication: High vertical leap is a key indicator of athleticism, beneficial for various positions.
Three-Quarter Court Sprint (0.0363)

Analysis: This metric measures a player's speed over a short distance, reflecting their quickness in transition plays.
Implication: Speed is critical for fast breaks and defensive recoveries, making this an important feature.
Weight in Kilograms (0.0360)

Analysis: Weight is a basic physical attribute that, combined with height, contributes to overall body composition analysis.
Implication: Teams consider weight to ensure players have the necessary mass for their playing style and position.
Modified Lane Agility (0.0355)

Analysis: This combines elements of agility and endurance, providing a comprehensive view of a player's mobility.
Implication: Enhanced agility metrics help in understanding a player's ability to maintain performance throughout the game.
Conclusion
This analysis highlights the diverse range of physical and performance metrics that contribute to a player's draft prospects. Features such as the year of participation in the Combine, body fat percentage, and various agility and strength measurements underscore the multifaceted evaluation process NBA teams employ. By focusing on these key metrics, teams can better assess a player's readiness and potential impact in the league.

# Select important features based on their names
important_feature_names = important_features_df['Feature'].values
important_feature_indices = [list(all_feature_names).index(name) for name in important_feature_names]

# Use only the important features for the next step
X_train_important = X_train[:, important_feature_indices]
X_test_important = X_test[:, important_feature_indices]

# Train and evaluate Gradient Boosting with important features
model_important = GradientBoostingClassifier()
model_important.fit(X_train_important, y_train)
y_pred_important = model_important.predict(X_test_important)
y_pred_prob_important = model_important.predict_proba(X_test_important)[:, 1]

# Calculate evaluation metrics
accuracy_important = accuracy_score(y_test, y_pred_important)
precision_important = precision_score(y_test, y_pred_important, average='weighted')
recall_important = recall_score(y_test, y_pred_important, average='weighted')
f1_important = f1_score(y_test, y_pred_important, average='weighted')
roc_auc_important = roc_auc_score(y_test, y_pred_prob_important)

tn_important, fp_important, fn_important, tp_important = confusion_matrix(y_test, y_pred_important).ravel()
specificity_important = tn_important / (tn_important + fp_important) if (tn_important + fp_important) != 0 else 'N/A'

# Display results
results_important = {
    'Accuracy': accuracy_important,
    'Precision': precision_important,
    'Recall': recall_important,
    'F1 Score': f1_important,
    'ROC-AUC': roc_auc_important,
    'Specificity': specificity_important
}

print(results_important)

Commentary:
This process enhances the model by focusing on key features for predicting NBA draft outcomes. Initially, a Gradient Boosting model identified feature importance. Features with an importance score greater than 0.02 were selected to retrain the model, aiming to improve recall. The primary metric, recall, increased from 0.6420 to 0.6516, enhancing the model's ability to correctly identify all drafted players and minimize false negatives. This ensures comprehensive identification of potential draftees, crucial for effective scouting and decision-making


# Save the Best Model

import joblib

# Save the model
best_model = model_important
joblib.dump(best_model, 'nba_draft_prediction_model_JERRYLAI.pkl')


1. Load the Best Model

import joblib

# Load the best model
best_model = joblib.load('nba_draft_prediction_model_JERRYLAI.pkl')

2. Gather Real Data for Kevin Durant and Bronny James
Let's find the real data for these players.

Kevin Durant
Height (without shoes): 81.75 inches (6'9.75")
Weight: 240 lbs
Wingspan: 87.5 inches
Standing Reach: 96.0 inches
Vertical Leap (Standing): 33.5 inches
Vertical Leap (Max): 39.0 inches
Reps Bench Press: 3
Lane Agility Time: 11.18 seconds
Three Quarter Sprint Time: 3.45 seconds
Body Fat Percentage: 6.9%
yearCombine:2007


Bronny James
Height (without shoes): 74.75 inches (6'2.75")
Weight: 180 lbs
Wingspan: 80.0 inches
Standing Reach: 95.0 inches
Vertical Leap (Standing): 31.5 inches
Vertical Leap (Max): 35.5 inches
Reps Bench Press: 10
Lane Agility Time: 11.00 seconds
Three Quarter Sprint Time: 3.25 seconds
Body Fat Percentage: 7.2%
yearCombine:2024


3. Create DataFrame for Kevin Durant and Bronny James

import pandas as pd

# Data for Kevin Durant and Bronny James
data = {
    'heightWOShoesInches': [81.75, 74.75],
    'weightLBS': [240, 180],
    'wingspanInches': [87.5, 80.0],
    'reachStandingInches': [96.0, 95.0],
    'verticalLeapStandingInches': [33.5, 31.5],
    'verticalLeapMaxInches': [39.0, 35.5],
    'repsBenchPress135': [3, 10],
    'timeLaneAgility': [11.18, 11.00],
    'timeThreeQuarterCourtSprint': [3.45, 3.25],
    'pctBodyFat': [6.9, 7.2],
    'yearCombine': [2007, 2024]
}

players_df = pd.DataFrame(data, index=['Kevin Durant', 'Bronny James'])

4. Feature Engineering and Standardization

# Feature Engineering
def feature_engineering(df):
    df['weightKG'] = df['weightLBS'] * 0.453592
    df['heightM'] = df['heightWOShoesInches'] * 0.0254
    df['BMI'] = df['weightKG'] / (df['heightM'] ** 2)
    return df

# Apply feature engineering
players_df = feature_engineering(players_df)

# Standardize the numeric features
from sklearn.preprocessing import StandardScaler
import numpy as np

numeric_features = players_df.columns
scaler = StandardScaler()
players_df[numeric_features] = scaler.fit_transform(players_df[numeric_features])

5. Prediction

# Predict draft status
predictions = best_model.predict(players_df)
predicted_probabilities = best_model.predict_proba(players_df)[:, 1]

# Display results
for player, prediction, probability in zip(players_df.index, predictions, predicted_probabilities):
    status = 'Drafted' if prediction else 'Not Drafted'
    print(f"{player}: {status} (Probability: {probability:.2f})")

Results:
Kevin Durant: Drafted (Probability: 0.90)
Bronny James: Drafted (Probability: 0.68)

Proof:
    1.Kevin Durant was drafted in the 2007 NBA Draft. He was selected as the second overall pick by the Seattle SuperSonics, who later became the Oklahoma City Thunderâ€‹ (Sporting News)â€‹.
    
    2.The opinions on whether Bronny James will be drafted in the 2024 NBA Draft vary widely:

    Second-Round Projections: Many mock drafts, including those from The Sporting News and The Ringer, project Bronny to be selected in the second round, often by the Los Angeles Lakers. This is partly influenced by the prospect of pairing him with his father, LeBron Jamesâ€‹ (Sporting News)â€‹â€‹ (Sporting News)â€‹.

    Possible Teams: Besides the Lakers, other teams like the Utah Jazz and Miami Heat have shown interest. The Jazz, holding the 32nd pick, and the Heat, with the 15th and 43rd picks, are potential landing spotsâ€‹ (Yahoo Sports)â€‹.

    Concerns and Challenges: Despite the interest, some sources are skeptical about Bronny's draft prospects due to his modest performance at USC and the cardiac arrest incident that affected his season. ESPN's latest mock draft does not include Bronny, highlighting concerns about his readiness and overall impactâ€‹ (Sporting News)â€‹â€‹ (Oddspedia)â€‹.

    Draft Odds: Betting odds suggest that the Lakers are the most likely team to draft Bronny, but they also indicate uncertainty about his draft position, reflecting the mixed opinions among analystsâ€‹ (Oddspedia)â€‹.

    Overall, while there is significant interest and some optimistic projections, there are also doubts and uncertainties about Bronny James' draft status, making it a highly debated topic among experts and analysts.
    


# Ensure you're in the correct environment and have installed SHAP
try:
    import shap
except ModuleNotFoundError:
    # Install SHAP if it's not already installed
    import sys
    !{sys.executable} -m pip install shap

import shap
import numpy as np
import matplotlib.pyplot as plt

# Assuming X_train and best_model are already defined and preprocessed
explainer = shap.TreeExplainer(best_model)  # Initialize SHAP explainer for tree-based models
shap_values = explainer.shap_values(X_train)  # Calculate SHAP values for training data

# Get the column indices of the important features after one-hot encoding
categorical_feature_names = preprocessor.transformers_[1][1].get_feature_names_out(categorical_features)
all_feature_names = np.concatenate([numeric_feature_names, categorical_feature_names])
important_feature_indices = [list(all_feature_names).index(name) for name in important_feature_names]

# Filter SHAP values for only the important features
shap_values_important = shap_values[:, important_feature_indices]

# Create SHAP summary plot
shap.summary_plot(shap_values_important, X_train[:, important_feature_indices], feature_names=important_feature_names, show=False)

# Get the current axis
ax = plt.gca()

# Set feature names to white
ax.tick_params(axis='y', colors='white')

# Set custom x-axis ticks and labels
ax.set_xticks([-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2])
ax.set_xticklabels(['-2', '-1.5', '-1', '-0.5', '0', '0.5', '1', '1.5', '2'], color='white')  # Set labels and color

# Show the plot
plt.show()




Granular Explanation of SHAP Values and Their Implications and Applications
1.yearCombine

*Impact Range: SHAP values range from -1 to 1, indicating a significant influence on the prediction results.
*Color Distribution: Red points are mainly in the positive range, while blue points are in the negative range. This shows that higher yearCombine values (more red) have a more positive impact on predictions, while lower values (more blue) have a negative impact.
*Implications: Newer years often mean advancements in player physical fitness and training techniques.
*Application: Useful for determining which rookies are more likely to perform well in games.

2.verticalLeapStandingInches

*Impact Range: SHAP values range from -1.5 to 1.5, showing a significant impact.
*Color Distribution: Red points appear in both positive and negative ranges, indicating that high values (red) can have either positive or negative impacts depending on other feature values.
*Implications: Standing vertical leap reflects a playerâ€™s explosiveness and jumping ability, crucial for basketball.
*Application: Used to identify players who excel in defense and offensive rebounding.

3.wingspanInches

*Impact Range: SHAP values range from -1 to 1, showing a significant impact.
*Color Distribution: Red points are concentrated in the positive range, and blue points in the negative range, indicating that higher wingspan values (more red) positively impact predictions.
*Implications: Wingspan is related to defensive coverage and interception ability.
*Application: Helps select defensive players, especially those effective at blocking shots and intercepting passes.

4.reachStandingInches

*Impact Range: SHAP values range from -1.5 to 1.5.
*Color Distribution: High values (red) are in the positive range, and low values (blue) are in the negative range, indicating higher reachStandingInches values positively impact predictions.
*Implications: Standing reach height reflects the playerâ€™s advantage in offensive and defensive coverage.
*Application: Useful for evaluating centers and forwards for rebounding and blocking potential.

5.verticalLeapMaxInches

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: Broad distribution with high values (red) mainly showing a positive impact.
*Implications: Maximum vertical leap indicates a playerâ€™s peak explosiveness and jumping ability.
*Application: Used to select players capable of efficient shot-blocking and rebounding.

6.timeThreeQuarterCourtSprint

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: Even distribution indicates that changes in this feature have a stable impact on predictions.
*Implications: Reflects the playerâ€™s speed and acceleration ability.
*Application: Evaluates the speed and quick response ability of guards and fast-break players.

7.repsBenchPress135

*Impact Range: SHAP values range from -0.5 to 0.5.
*Color Distribution: High values (red) are in the positive range, indicating higher repsBenchPress135 values positively impact predictions.
*Implications: Reflects a playerâ€™s upper body strength and endurance.
*Application: Used to evaluate a playerâ€™s strength and endurance in physical confrontations.

8.timeModifiedLaneAgility

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: Broad distribution with high values (red) having a positive impact.
*Implications: Reflects a playerâ€™s agility and flexibility.
*Application: Useful for evaluating guards and players requiring high agility.

9.timeLaneAgility

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: Similar to timeModifiedLaneAgility, with high values (red) having a positive impact.
*Implications: Reflects a playerâ€™s agility and quick directional change ability.
*Application: Helps select players needing quick movement and directional change ability.

10.weightKG

*Impact Range: SHAP values range from -0.5 to 0.5.
*Color Distribution: High values (red) are in the positive range, indicating higher weightKG values positively impact predictions.
*Implications: Reflects a playerâ€™s strength and ability to handle physical confrontations.
*Application: Evaluates playersâ€™ advantage in physical confrontations, especially inside players.

11.pctBodyFat

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: High values (red) are in the positive range, indicating higher pctBodyFat values positively impact predictions.
*Implications: Reflects the playerâ€™s body composition and health status.
*Application: Used to assess playersâ€™ physical condition and endurance.

12.heightM

*Impact Range: SHAP values range from -1 to 1.
*Color Distribution: High values (red) are in the positive range, indicating higher heightM values positively impact predictions.
*Implications: Height directly impacts a playerâ€™s advantage in rebounds and defense.
*Application: Used to select inside players needing height advantage.

13.widthHandInches

*Impact Range: SHAP values range from -0.5 to 0.5.
*Color Distribution: High values (red) are in the positive range, indicating higher widthHandInches values positively impact predictions.
*Implications: Reflects a playerâ€™s ability to grip and control the ball.
*Application: Helps select players with good ball-handling skills.

14.BMI

*Impact Range: SHAP values range from -0.5 to 0.5.
*Color Distribution: High values (red) are in the positive range, indicating higher BMI values positively impact predictions.
*Implications: Indicates a playerâ€™s body composition and fitness level.
*Application: Used to assess playersâ€™ overall physical condition and fitness.

Summary
These SHAP plots show the impact of different features on prediction results. By examining the color and SHAP value distribution, it becomes clear which feature values have a more significant positive or negative impact on predictions. This information helps in understanding the modelâ€™s behavior, optimizing feature engineering, and training models. Understanding the implications and applications of each feature allows for more effective player selection and training programs.














